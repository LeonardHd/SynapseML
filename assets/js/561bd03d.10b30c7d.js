"use strict";(self.webpackChunksynapseml=self.webpackChunksynapseml||[]).push([[2185],{3905:(e,t,r)=>{r.d(t,{Zo:()=>p,kt:()=>f});var n=r(67294);function a(e,t,r){return t in e?Object.defineProperty(e,t,{value:r,enumerable:!0,configurable:!0,writable:!0}):e[t]=r,e}function o(e,t){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),r.push.apply(r,n)}return r}function i(e){for(var t=1;t<arguments.length;t++){var r=null!=arguments[t]?arguments[t]:{};t%2?o(Object(r),!0).forEach((function(t){a(e,t,r[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):o(Object(r)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(r,t))}))}return e}function c(e,t){if(null==e)return{};var r,n,a=function(e,t){if(null==e)return{};var r,n,a={},o=Object.keys(e);for(n=0;n<o.length;n++)r=o[n],t.indexOf(r)>=0||(a[r]=e[r]);return a}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(n=0;n<o.length;n++)r=o[n],t.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(e,r)&&(a[r]=e[r])}return a}var s=n.createContext({}),l=function(e){var t=n.useContext(s),r=t;return e&&(r="function"==typeof e?e(t):i(i({},t),e)),r},p=function(e){var t=l(e.components);return n.createElement(s.Provider,{value:t},e.children)},m={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},u=n.forwardRef((function(e,t){var r=e.components,a=e.mdxType,o=e.originalType,s=e.parentName,p=c(e,["components","mdxType","originalType","parentName"]),u=l(r),f=a,g=u["".concat(s,".").concat(f)]||u[f]||m[f]||o;return r?n.createElement(g,i(i({ref:t},p),{},{components:r})):n.createElement(g,i({ref:t},p))}));function f(e,t){var r=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var o=r.length,i=new Array(o);i[0]=u;var c={};for(var s in t)hasOwnProperty.call(t,s)&&(c[s]=t[s]);c.originalType=e,c.mdxType="string"==typeof e?e:a,i[1]=c;for(var l=2;l<o;l++)i[l]=r[l];return n.createElement.apply(null,i)}return n.createElement.apply(null,r)}u.displayName="MDXCreateElement"},97308:(e,t,r)=>{r.r(t),r.d(t,{assets:()=>s,contentTitle:()=>i,default:()=>m,frontMatter:()=>o,metadata:()=>c,toc:()=>l});var n=r(83117),a=(r(67294),r(3905));const o={title:"Publication - Large-Scale Intelligent Microservices",description:"Large-Scale Intelligent Microservices",keywords:["microservices","IEEE Big Data","paper"]},i=void 0,c={permalink:"/SynapseML/blog/2020/12/01/Large-Scale Intelligent Microservices",source:"@site/blog/2020-12-01-Large-Scale Intelligent Microservices.md",title:"Publication - Large-Scale Intelligent Microservices",description:"Large-Scale Intelligent Microservices",date:"2020-12-01T00:00:00.000Z",formattedDate:"December 1, 2020",tags:[],readingTime:.84,hasTruncateMarker:!0,authors:[],frontMatter:{title:"Publication - Large-Scale Intelligent Microservices",description:"Large-Scale Intelligent Microservices",keywords:["microservices","IEEE Big Data","paper"]},prevItem:{title:"What is SynapseML?",permalink:"/SynapseML/blog/overview"},nextItem:{title:"MMLSpark: empowering AI for Good with Mark Hamilton",permalink:"/SynapseML/blog/2019/10/02/MMLSpark empowering AI for Good with Mark Hamilton"}},s={authorsImageUrls:[]},l=[],p={toc:l};function m(e){let{components:t,...r}=e;return(0,a.kt)("wrapper",(0,n.Z)({},p,r,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"The process of deploying Machine Learning (ML) algorithms within databases is challenging. The varied computational footprints of modern ML algorithms and the myriad of database technologies, each with their own restrictive syntax, make such tasks more than a little complex. We introduce an Apache Spark-based micro-service orchestration "," framework that extends database operations to include web service primitives. Our system can orchestrate web services across hundreds of machines and takes full advantage of cluster, thread, and asynchronous parallelism. Using this framework, we provide large scale clients for intelligent services such as speech, vision, search, anomaly detection, and text analysis. These clients allow users to integrate ready-to-use intelligence into any datastore with an Apache Spark connector. To eliminate much of the overhead from network communication, we also introduce a low-latency containerized version of our architecture. We demonstrate that the services we investigate are competitive on several important benchmarks. Finally, we present two applications of this framework to create intelligent search engines and real-time auto race analytics systems."),(0,a.kt)("p",null,(0,a.kt)("a",{parentName:"p",href:"https://www.microsoft.com/en-us/research/publication/large-scale-services/"},"Read More")))}m.isMDXComponent=!0}}]);